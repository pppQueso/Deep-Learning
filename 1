import pandas as pd
import numpy as np
import torch

features = pd.read_csv('train.csv')[['LotArea','YearBuilt']]
labels = pd.read_csv('train.csv')[['SalePrice']]
features = np.array(features)
features = torch.Tensor(features)
labels = np.array(labels)
labels = torch.Tensor(labels)
from sklearn.model_selection import train_test_split

# 将原始数据切分为 训练集 train_set & 测试集 test_set，切分比例为 30% : 70%，固定随机数种子为 2024
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=2024)
import torch.utils.data as Data

batch_size = 16

train_dataset = Data.TensorDataset(X_train, y_train)   # Dataset
test_dataset = Data.TensorDataset(X_test, y_test)

train_dataloader = Data.DataLoader(train_dataset, batch_size, shuffle=True)  # DataLoader
test_dataloader = Data.DataLoader(test_dataset, batch_size, shuffle=True)
for idx, (x, y) in enumerate(train_dataloader):
    print(f"index of {idx}, feature: {x.shape}, label: {y.shape}")
import torch
import torch.nn as nn


class LinearNet(nn.Module):
    """ 线性神经网络模型 """
    def __init__(self, in_feature, out_feature):
        """ 模型构造方法 """
        super().__init__()  # 调用 nn.Module 这个父类的初始化方法对该模型进行初始化
        self.linear = nn.Linear(in_feature, out_feature)  # nn.Module
        self.activation = nn.ReLU()
        
    def forward(self, x):
        """ 前向传播函数 """
        y = self.linear(x)
        y = self.activation(y)
        return y
x, y = train_dataset[:4]  # -> (a, b)
x, y,len(train_dataset)
import torch.optim as optim
# 损失函数
loss = nn.MSELoss()



# 模型
model = LinearNet(2, 1)

# 优化器
optimizer = optim.Adam(model.parameters(), lr=10)
def train_model(model, dataloader):
    model.train()

    total_loss = 0.
    for idx, (x, y) in enumerate(dataloader):
        y_pred = model(x)
        cur_loss = loss(y_pred, y)
        optimizer.zero_grad()
        cur_loss.backward()
        optimizer.step()

        total_loss += cur_loss.item()
    print(f"Train loss: {total_loss/len(train_dataset)}")
num_epoch = 5
for i in range(num_epoch):
    train_model(model, train_dataloader)
def test_model(model, dataloader):
    model.eval()

    total_loss = 0.
    for idx, (x, y) in enumerate(dataloader):
        y_pred = model(x)
        cur_loss = loss(y_pred, y)
        total_loss += cur_loss.item()
    print(f"Test loss: {total_loss/len(test_dataset)}")
num_epoch = 1000
for i in range(num_epoch):
    print(f"==== Epoch {i} ====")
    train_model(model, train_dataloader)
    test_model(model, test_dataloader)
class MLPNet(nn.Module):
    """ 线性神经网络模型 """
    def __init__(self, in_feature: int, out_feature: int, hidden: list=[256, 128]):
        """ 模型构造方法 """
        super().__init__()  # 调用 nn.Module 这个父类的初始化方法对该模型进行初始化
        self.linear_1 = nn.Linear(in_feature, 256)  # nn.Module
        self.linear_2 = nn.Linear(256, 128)
        self.linear_3 = nn.Linear(128, out_feature)
        self.activation = nn.ReLU()
        self.softmax = nn.Softmax()  # 将同一纬度的数同时压缩，使得其总和为1
        
    def forward(self, x):
        """ 前向传播函数 """
        h = self.activation(self.linear_1(x))
        h = self.activation(self.linear_2(h))
        h = self.activation(self.linear_3(h))
        
        return self.softmax(h)
model = MLPNet(2, 1)
def train_model(model, dataloader):
    model.train()

    total_loss = 0.
    for idx, (x, y) in enumerate(dataloader):
        y_pred = model(x)
        cur_loss = loss(y_pred, y)
        optimizer.zero_grad()
        cur_loss.backward()
        optimizer.step()

        total_loss += cur_loss.item()
    print(f"Train loss: {total_loss/len(train_dataset)}")
    
num_epoch = 100
for i in range(num_epoch):
    train_model(model, train_dataloader)
